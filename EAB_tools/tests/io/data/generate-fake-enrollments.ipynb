{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code was mostly created by ChatGPT\n",
    "from __future__ import annotations\n",
    "\n",
    "import random\n",
    "from typing import Any\n",
    "\n",
    "from faker import Faker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  # Also sets the random seed for `pandas`\n",
    "Faker.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_records = 85_253"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_per_course_distribution: dict[float, float] = {\n",
    "    1: 0.5288,\n",
    "    2: 0.2028,\n",
    "    3: 0.0946,\n",
    "    4: 0.0601,\n",
    "    5: 0.0274,\n",
    "    6: 0.0286,\n",
    "    7: 0.0211,\n",
    "    8: 0.0033,\n",
    "    9: 0.0030,\n",
    "    10: 0.0051,\n",
    "    11: 0.0079,\n",
    "    12: 0.0031,\n",
    "    13: 0.0032,\n",
    "    15: 0.0029,\n",
    "    18: 0.0014,\n",
    "    19: 0.0016,\n",
    "    20: 0.0026,\n",
    "    24: 0.0012,\n",
    "    35: 0.0013,\n",
    "}\n",
    "\n",
    "instructors_per_course_distribution: dict[float, float] = {\n",
    "    0: 0.0609,\n",
    "    1: 0.9224,\n",
    "    2: 0.0168,\n",
    "}\n",
    "\n",
    "sections_per_instructor_distribution: dict[float, float] = {\n",
    "    1: 0.3148,\n",
    "    2: 0.3148,\n",
    "    3: 0.1872,\n",
    "    4: 0.0922,\n",
    "    5: 0.0425,\n",
    "    6: 0.0192,\n",
    "    7: 0.0149,\n",
    "    8: 0.0055,\n",
    "    9: 0.0036,\n",
    "    10: 0.0035,\n",
    "    15: 0.0018,\n",
    "}\n",
    "\n",
    "students_per_section_distribution: dict[float, float] = {\n",
    "    1: 0.0579,\n",
    "    2: 0.0373,\n",
    "    3: 0.0290,\n",
    "    4: 0.0413,\n",
    "    5: 0.0284,\n",
    "    6: 0.0472,\n",
    "    7: 0.0332,\n",
    "    8: 0.0263,\n",
    "    9: 0.0402,\n",
    "    10: 0.0409,\n",
    "    11: 0.0329,\n",
    "    12: 0.0358,\n",
    "    13: 0.0276,\n",
    "    14: 0.0274,\n",
    "    15: 0.0225,\n",
    "    16: 0.0326,\n",
    "    17: 0.0298,\n",
    "    18: 0.0215,\n",
    "    19: 0.0219,\n",
    "    20: 0.0158,\n",
    "    21: 0.0175,\n",
    "    22: 0.0194,\n",
    "    23: 0.0137,\n",
    "    24: 0.0176,\n",
    "    25: 0.0211,\n",
    "    26: 0.0209,\n",
    "    27: 0.0094,\n",
    "    28: 0.0167,\n",
    "    29: 0.0246,\n",
    "    30: 0.0110,\n",
    "    31: 0.0151,\n",
    "    32: 0.0112,\n",
    "    33: 0.0122,\n",
    "    34: 0.0130,\n",
    "    35: 0.0148,\n",
    "    36: 0.0157,\n",
    "    37: 0.0073,\n",
    "    38: 0.0159,\n",
    "    39: 0.0080,\n",
    "    40: 0.0091,\n",
    "    41: 0.0053,\n",
    "    42: 0.0057,\n",
    "    43: 0.0065,\n",
    "    44: 0.0040,\n",
    "    45: 0.0016,\n",
    "    46: 0.0033,\n",
    "    47: 0.0046,\n",
    "    48: 0.0027,\n",
    "    49: 0.0015,\n",
    "    50: 0.0040,\n",
    "    51: 0.0035,\n",
    "    52: 0.0016,\n",
    "    53: 0.0012,\n",
    "    54: 0.0019,\n",
    "    55: 0.0010,\n",
    "    56: 0.0020,\n",
    "    57: 0.0020,\n",
    "    59: 0.0013,\n",
    "    60: 0.0006,\n",
    "    63: 0.0005,\n",
    "    69: 0.0012,\n",
    "    111: 0.0005,\n",
    "}\n",
    "\n",
    "classifications_distribution: dict[str, float] = {\n",
    "    \"Foo (Winter 2024)\": 0.6120,\n",
    "    \"Foo (Fall 2023)\": 0.1859,\n",
    "    \"Graduate (Winter 2024)\": 0.0573,\n",
    "    \"None\": 0.0379,\n",
    "    \"Foo (Spring 2024)\": 0.0369,\n",
    "    \"Graduate (Fall 2023)\": 0.0160,\n",
    "    \"Foo (Spring 2023)\": 0.0151,\n",
    "    \"Foo (Summer 2023)\": 0.0130,\n",
    "    \"Foo (Winter 2023)\": 0.0064,\n",
    "    \"Foo (Fall 2022)\": 0.0053,\n",
    "    \"Graduate (Spring 2023)\": 0.0015,\n",
    "    \"Foo (Spring 2022)\": 0.0017,\n",
    "    \"Graduate (Summer 2023)\": 0.0014,\n",
    "    \"Graduate (Spring 2024)\": 0.0013,\n",
    "    \"Graduate (Winter 2023)\": 0.0010,\n",
    "    \"Graduate (Fall 2022)\": 0.0005,\n",
    "    \"Graduate (Summer 2022)\": 0.0005,\n",
    "    \"Foo (Fall 2021)\": 0.0005,\n",
    "    \"Foo (Spring 2020)\": 0.0004,\n",
    "    \"Foo (Fall 2019)\": 0.0003,\n",
    "    \"Foo (Summer 2024)\": 0.0004,\n",
    "    \"Foo (Winter 2022)\": 0.0004,\n",
    "    \"Foo (Summer 2022)\": 0.0003,\n",
    "    \"Graduate (Fall 2018)\": 0.0002,\n",
    "    \"Graduate (Winter 2022)\": 0.0002,\n",
    "    \"Foo (Fall 2020)\": 0.0002,\n",
    "    \"Foo (Winter 2019)\": 0.0002,\n",
    "    \"Foo (Winter 2020)\": 0.0002,\n",
    "    \"Graduate (Winter 2018)\": 0.0002,\n",
    "    \"Graduate (Spring 2021)\": 0.0002,\n",
    "    \"Foo (Winter 2017)\": 0.0002,\n",
    "    \"Graduate (Winter 2021)\": 0.0002,\n",
    "    \"Graduate (Summer 2021)\": 0.0002,\n",
    "    \"Freshman (Winter 2024)\": 0.0001,\n",
    "    \"Foo (Winter 2021)\": 0.0001,\n",
    "    \"Foo (Spring 2016)\": 0.0001,\n",
    "    \"Graduate (Spring 2017)\": 0.0001,\n",
    "    \"Graduate (Summer 2020)\": 0.0001,\n",
    "    \"Graduate (Spring 2020)\": 0.0001,\n",
    "    \"Foo (Spring 2019)\": 0.0001,\n",
    "    \"Graduate (Fall 2020)\": 0.0001,\n",
    "    \"Graduate (Spring 2019)\": 0.0001,\n",
    "    \"Graduate (Spring 2022)\": 0.0001,\n",
    "    \"Foo (Summer 2021)\": 0.0001,\n",
    "    \"Graduate (Fall 2021)\": 0.0001,\n",
    "    \"Foo (Fall 2016)\": 0.0001,\n",
    "    \"Foo (Summer 2019)\": 0.0001,\n",
    "    \"Freshman (Fall 2022)\": 0.0001,\n",
    "    \"Graduate (Summer 2024)\": 0.0001,\n",
    "    \"Foo (Fall 2024)\": 0.0001,\n",
    "    \"Foo (Spring 2021)\": 0.0001,\n",
    "}\n",
    "\n",
    "num_courses_per_student_distribution: dict[float, float] = {\n",
    "    1: 0.1870,\n",
    "    2: 0.2159,\n",
    "    3: 0.2484,\n",
    "    4: 0.1562,\n",
    "    5: 0.0881,\n",
    "    6: 0.0480,\n",
    "    7: 0.0226,\n",
    "    8: 0.0105,\n",
    "    9: 0.0067,\n",
    "    10: 0.0056,\n",
    "    11: 0.0018,\n",
    "    12: 0.0053,\n",
    "    13: 0.0027,\n",
    "    14: 0.0005,\n",
    "    15: 0.0001,\n",
    "    16: 0.0005,\n",
    "    17: 0.0002,\n",
    "}\n",
    "\n",
    "credit_hours_per_student_distribution: dict[float, float] = {\n",
    "    0: 0.14,\n",
    "    1: 0.05,\n",
    "    2: 0.07,\n",
    "    3: 0.26,\n",
    "    4: 0.01,\n",
    "    5: 0.44,\n",
    "    6: 0.02,\n",
    "    12: 0.01,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_probs_sum_to_one(d: dict[Any, float]) -> dict[Any, float]:\n",
    "    \"\"\"Make sure the probabilities in dict values add up to one\"\"\"\n",
    "    return {key: value / sum(d.values()) for key, value in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EV(d: dict[float, float], normalize: bool = True) -> float:\n",
    "    \"\"\"Compute the expected value of a dict mapping `float`s to their probability or\n",
    "    to their weight (the latter if `normalize=True`)\"\"\"\n",
    "    if normalize:\n",
    "        d = make_probs_sum_to_one(d)\n",
    "    return sum(key * value for key, value in d.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sections_per_course = EV(sections_per_course_distribution)\n",
    "avg_instructors_per_course = EV(instructors_per_course_distribution)\n",
    "avg_sections_per_instructor = EV(sections_per_instructor_distribution)\n",
    "avg_students_per_section = EV(students_per_section_distribution)\n",
    "avg_courses_per_student = EV(num_courses_per_student_distribution)\n",
    "avg_credit_hours_per_student = EV(credit_hours_per_student_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_dict(\n",
    "    distribution: dict[Any, float],\n",
    "    size: int | None = None,\n",
    "    normalize: bool = True,\n",
    "    replace: bool = True,\n",
    ") -> Any:\n",
    "    \"\"\"Take a sample from a `dict`, where the keys are the sample space and the\n",
    "    values are the weights of each key,\"\"\"\n",
    "    if normalize:\n",
    "        distribution = make_probs_sum_to_one(distribution)\n",
    "    keys, weights = zip(*distribution.items())\n",
    "    return np.random.choice(keys, p=weights, size=size, replace=replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of unique students based on the average number of courses per\n",
    "# student\n",
    "n_unique_students = int(n_records / avg_courses_per_student)\n",
    "\n",
    "# Generate unique student data\n",
    "unique_students = pd.DataFrame(\n",
    "    {\n",
    "        \"Student ID\": [\n",
    "            # The builtin `random.sample` method from the Python standard lib can\n",
    "            # efficiently sample from `range` objects, while `np.random.sample` needs to\n",
    "            # construct the entire list in memory first.\n",
    "            f\"ID{rand_id:09}\"\n",
    "            for rand_id in random.sample(range(10**9), n_unique_students)\n",
    "        ],\n",
    "        \"Student Alternate ID\": np.NaN,\n",
    "        \"Student Name\": [fake.name() for _ in range(n_unique_students)],\n",
    "        \"Student E-mail\": [fake.email() for _ in range(n_unique_students)],\n",
    "        \"Classification\": sample_from_dict(\n",
    "            classifications_distribution, size=n_unique_students\n",
    "        ),\n",
    "        \"Major\": np.random.choice(\n",
    "            [\n",
    "                \"Computer Science\",\n",
    "                \"Business Administration\",\n",
    "                \"Psychology\",\n",
    "                \"Education\",\n",
    "                \"Engineering\",\n",
    "            ],\n",
    "            n_unique_students,\n",
    "        ),\n",
    "        \"Credit Hours\": sample_from_dict(\n",
    "            credit_hours_per_student_distribution, size=n_unique_students\n",
    "        ),\n",
    "    }\n",
    ").replace(\"None\", np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Categories\n",
    "def select_categories() -> str | None:\n",
    "    categories = []\n",
    "\n",
    "    def _include_category(chance: float = 0.9) -> bool:\n",
    "        \"\"\"Randomly decide to include a category or not\"\"\"\n",
    "        return np.random.rand() < chance\n",
    "\n",
    "    campus_options = {\"On-line\": 0.5, \"Main Campus\": 0.4, \"Satellite Campus\": 0.1}\n",
    "    graduated_options = {  # Mutually exclusive with certain other categories\n",
    "        \"Graduated: Yes\": 0.1,\n",
    "        \"Graduated: No\": 0.9,\n",
    "    }\n",
    "    level_options = [\n",
    "        \"Undergraduate\",\n",
    "        \"Graduate\",\n",
    "    ]\n",
    "    hold_types = [\"Hold: Financial\", \"Hold: Academic\", \"Hold: Administrative\"]\n",
    "    comp_rate_options = {\n",
    "        \"Completion Rate: >= 66.67%\": 0.75,\n",
    "        \"Completion Rate: < 66.67%\": 0.25,\n",
    "    }\n",
    "    start_term_options = [\n",
    "        f\"Start Term: {season} {year}\"\n",
    "        for year in range(2000, 2025)\n",
    "        for season in [\"Fall\", \"Winter\", \"Spring\", \"Summer\"]\n",
    "    ]\n",
    "    start_term_options_dict = {\n",
    "        term: float(i) for i, term in enumerate(start_term_options, start=1)\n",
    "    }\n",
    "    term_status_options = [  # Mutually exclusive with \"Graduated: Yes\"\n",
    "        \"Term Status: Registered\",\n",
    "        \"Term Status: Not Registered\",\n",
    "    ]\n",
    "    fafsa_options = [  # Mutually exclusive with \"Graduated: Yes\"\n",
    "        \"FAFSA: Yes\",\n",
    "        \"FAFSA: No\",\n",
    "    ]\n",
    "\n",
    "    # Build up categories one-by-one, randomly deciding which will be included.\n",
    "    if _include_category():\n",
    "        categories.append(f\"Campus: {sample_from_dict(campus_options)}\")\n",
    "    if _include_category():\n",
    "        categories.append(sample_from_dict(graduated_options))\n",
    "    if _include_category():\n",
    "        categories.append(np.random.choice(level_options))\n",
    "    if _include_category(chance=0.10):  # Only 10% chance of showing a Hold\n",
    "        categories.append(np.random.choice(hold_types))\n",
    "    if _include_category():\n",
    "        categories.append(sample_from_dict(comp_rate_options))\n",
    "    if _include_category():\n",
    "        categories.append(sample_from_dict(start_term_options_dict))\n",
    "\n",
    "    if \"Graduated: Yes\" not in categories:\n",
    "        # We can only be here if you do NOT show \"Graduated: Yes\"\n",
    "        if _include_category():\n",
    "            categories.append(np.random.choice(term_status_options))\n",
    "        if _include_category():\n",
    "            categories.append(np.random.choice(fafsa_options))\n",
    "\n",
    "    return \", \".join(categories) if categories else None\n",
    "\n",
    "\n",
    "unique_students[\"Categories\"] = [\n",
    "    select_categories() for _ in range(len(unique_students))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_tags() -> str | None:\n",
    "    tags = []\n",
    "\n",
    "    # General tags\n",
    "    general_tags = [\n",
    "        \"Honor Student\",\n",
    "        \"Scholarship Recipient\",\n",
    "        \"At Risk\",\n",
    "        \"Needs Tutoring\",\n",
    "        \"Athlete\",\n",
    "        \"International\",\n",
    "        \"Transfer\",\n",
    "    ]\n",
    "    # Tuples of mutually exclusive tags\n",
    "    mutually_exclusive_tags = [(\"Part-Time\", \"Full-Time\")]\n",
    "\n",
    "    max_tags = len(general_tags) + len(mutually_exclusive_tags)\n",
    "\n",
    "    def _include_tag(chance: float = 1 - 0.675 ** (1 / max_tags)) -> bool:\n",
    "        \"\"\"Randomly decide to include a tag or not.\n",
    "        We want a 67.5% chance that a student has no tags whatsoever.\n",
    "        With 8 possible tags, a little algebra reveals that the default chance must be\n",
    "        `1 - 0.675 ** (1 / num_possible_tags)`.\"\"\"\n",
    "        return np.random.rand() < chance\n",
    "\n",
    "    for tag in general_tags:\n",
    "        if _include_tag():\n",
    "            tags.append(tag)\n",
    "\n",
    "    for tuple_of_mutually_exclusive_tags in mutually_exclusive_tags:\n",
    "        if _include_tag():\n",
    "            tags.append(np.random.choice(tuple_of_mutually_exclusive_tags))\n",
    "\n",
    "    return \", \".join(tags) if tags else None\n",
    "\n",
    "\n",
    "unique_students[\"Tags\"] = [select_tags() for _ in range(len(unique_students))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cumulative_gpas(\n",
    "    length: int = 1,\n",
    ") -> np.typing.NDArray[np.floating[np.typing.NBitBase]]:\n",
    "    # Probabilities\n",
    "    prob_of_zero_gpa = 0.12\n",
    "    prob_of_high_gpa = 0.75 * (1 - prob_of_zero_gpa)  # 75% of non-zer\n",
    "\n",
    "    # Distribution counts\n",
    "    zero_gpas_count = np.random.binomial(length, prob_of_zero_gpa)\n",
    "    high_gpas_count = np.random.binomial(length - zero_gpas_count, prob_of_high_gpa)\n",
    "    low_gpas_count = length - zero_gpas_count - high_gpas_count\n",
    "\n",
    "    # Generate GPAs\n",
    "    zero_gpas = np.zeros(zero_gpas_count)\n",
    "    high_gpas = np.clip(np.random.normal(3.9, 0.4, size=high_gpas_count), 0, 4)\n",
    "    low_gpas = np.random.uniform(low=0, high=2.6, size=low_gpas_count)\n",
    "\n",
    "    # Combine and shuffle\n",
    "    all_gpas = np.concatenate([zero_gpas, high_gpas, low_gpas]).round(2)\n",
    "    np.random.shuffle(all_gpas)\n",
    "\n",
    "    all_gpas\n",
    "\n",
    "    return np.round(all_gpas, 2)\n",
    "\n",
    "\n",
    "unique_students[\"Cumulative GPA\"] = generate_cumulative_gpas(len(unique_students))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_courses_per_student = sample_from_dict(\n",
    "    num_courses_per_student_distribution, size=n_unique_students\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicate each student entry based on the number of courses they're taking\n",
    "replicated_students = unique_students.loc[\n",
    "    unique_students.index.repeat(num_courses_per_student)\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Course info\n",
    "# Generate a course schedule to assign students courses\n",
    "n_course_numbers_needed = np.ceil(\n",
    "    n_records / avg_students_per_section / avg_sections_per_course\n",
    ").astype(int)\n",
    "\n",
    "n_instructors_needed = np.ceil(n_records / avg_sections_per_instructor).astype(int)\n",
    "\n",
    "n_sections_per_course = sample_from_dict(\n",
    "    sections_per_course_distribution, size=n_course_numbers_needed\n",
    ")\n",
    "\n",
    "section_id_nums = iter(\n",
    "    np.random.choice(\n",
    "        np.arange(10**4, 10**5), size=sum(n_sections_per_course), replace=False\n",
    "    )\n",
    ")\n",
    "instructors = [\n",
    "    f\"{fake.last_name()}, {fake.first_name()} <{fake.email()}>\"\n",
    "    for _ in range(n_instructors_needed)\n",
    "]\n",
    "\n",
    "course_depts = (\n",
    "    \"AAS,AHS,ANT,ART,CAN,CIN,COM,CSC,DES,EAS,EDL,EDU,ENG,FME,GEN,HIS,HSC,LAN,LAS,LAW,\"\n",
    "    \"MED,MTH,MUS,NUR,OBG,OPH,PHA,PHE,PHY,PTH,QRM,RAC,ROM,SCI,SCW,SLV,SOC,STT,SUR,THR,\"\n",
    "    \"URB,VIA\"\n",
    ").split(\",\")\n",
    "course_number_ints = sample_from_dict(\n",
    "    {\n",
    "        i: 1 / i  # Higher course numbers map to lower probabilities\n",
    "        for i in range(95, 601)  # Course numbers can fall between 95 and 601\n",
    "    },\n",
    "    size=180,\n",
    "    replace=False,\n",
    ")\n",
    "\n",
    "\n",
    "# Add some course numbers that we definitely want to see\n",
    "course_numbers_set = set(course_number_ints) | {101, 200, 600, \"115L\", \"105H\"}\n",
    "course_numbers_list = sorted(f\"{x:03}\" for x in course_numbers_set)\n",
    "\n",
    "\n",
    "course_numbers = (\n",
    "    pd.Series(\n",
    "        f\"{course_dept}-{course_number:03}\"\n",
    "        for course_dept in course_depts\n",
    "        for course_number in course_numbers_list\n",
    "    )\n",
    "    .sample(n_course_numbers_needed)\n",
    "    .sort_values(ignore_index=True)\n",
    ")\n",
    "\n",
    "course_names = (\n",
    "    fake.unique.sentence(nb_words=6) for _ in range(n_course_numbers_needed)\n",
    ")\n",
    "\n",
    "\n",
    "course_schedule_list = []\n",
    "for course_number, course_name, num_course_sections in zip(\n",
    "    course_numbers, course_names, n_sections_per_course\n",
    "):\n",
    "    for _section_num in range(num_course_sections):\n",
    "        course_schedule_list.append(\n",
    "            {\n",
    "                \"Course Number\": course_number,\n",
    "                \"Course Name\": course_name,\n",
    "                \"Section\": next(section_id_nums),\n",
    "                \"Instructors\": random.choice(instructors),  # much faster than `np` 🤷‍♂️\n",
    "            }\n",
    "        )\n",
    "\n",
    "course_schedule = pd.DataFrame(course_schedule_list)\n",
    "\n",
    "course_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_course_assignments_list = []\n",
    "num_courses_for_each_student = sample_from_dict(\n",
    "    num_courses_per_student_distribution, size=n_unique_students\n",
    ")\n",
    "\n",
    "for student_id, num_courses in zip(\n",
    "    unique_students[\"Student ID\"], num_courses_for_each_student\n",
    "):\n",
    "    selected_sections = course_schedule.sample(n=num_courses)\n",
    "\n",
    "    # for index\n",
    "    # courses = course_schedule[course_schedule[\"Section\"].isin(selected_sections)]\n",
    "    for _index, selection_row in selected_sections.iterrows():\n",
    "        student_course_assignments_list.append(\n",
    "            {\n",
    "                \"Student ID\": student_id,\n",
    "                \"Course Number\": selection_row[\"Course Number\"],\n",
    "                \"Course Name\": selection_row[\"Course Name\"],\n",
    "                \"Section\": selection_row[\"Section\"],\n",
    "                \"Instructors\": selection_row[\"Instructors\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "replicated_students = pd.DataFrame(student_course_assignments_list).merge(\n",
    "    right=unique_students, how=\"left\", validate=\"many_to_one\"\n",
    ")\n",
    "\n",
    "replicated_students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrollment info\n",
    "replicated_students[\"Dropped?\"] = sample_from_dict(\n",
    "    {\"Yes\": 0.24, \"No\": 0.76}, size=len(replicated_students)\n",
    ")\n",
    "replicated_students[\"Dropped Date\"] = dropped_dates = [\n",
    "    fake.date_between(start_date=\"-1y\", end_date=\"today\") if drop == \"Yes\" else None\n",
    "    for drop in replicated_students[\"Dropped?\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add other enrollment-specific information (e.g., grades, attendance) in a similar\n",
    "# manner\n",
    "replicated_students[\"Midterm Grade\"] = np.random.choice(\n",
    "    [\"A\", \"B\", \"C\", \"D\", \"F\"], len(replicated_students)\n",
    ")\n",
    "replicated_students[\"Final Grade\"] = np.random.choice(\n",
    "    [\"A\", \"B\", \"C\", \"D\", \"F\"], len(replicated_students)\n",
    ")\n",
    "replicated_students[\"Total Progress Reports\"] = np.random.poisson(\n",
    "    0.4, len(replicated_students)\n",
    ")\n",
    "replicated_students[\"Absences\"] = np.random.poisson(0.5, len(replicated_students))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schedule information\n",
    "replicated_students[\"Start Date\"] = [\n",
    "    fake.date_between(start_date=\"-3m\", end_date=\"+3m\")\n",
    "    for _ in range(len(replicated_students))\n",
    "]\n",
    "replicated_students[\"End Date\"] = [\n",
    "    sd + pd.Timedelta(weeks=16) for sd in replicated_students[\"Start Date\"]\n",
    "]\n",
    "replicated_students[\"Start Time\"] = [\n",
    "    f\"{hour}:00 AM CT\"\n",
    "    for hour in np.random.choice(range(8, 12), len(replicated_students))\n",
    "]\n",
    "replicated_students[\"End Time\"] = [\n",
    "    f\"{hour + np.random.choice([1, 2, 3])}:00 PM CT\"\n",
    "    for hour in np.random.choice(range(1, 5), len(replicated_students))\n",
    "]\n",
    "replicated_students[\"Class Days\"] = [\n",
    "    \", \".join(\n",
    "        np.random.choice(\n",
    "            [\"M\", \"T\", \"W\", \"R\", \"F\", \"Sa\"], size=np.random.randint(1, 3), replace=False\n",
    "        )\n",
    "    )\n",
    "    for _ in range(len(replicated_students))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "# and ensure that the dataframe is not longer than `n_records`\n",
    "df_unordered_columns = replicated_students.iloc[:n_records]\n",
    "\n",
    "# Order the columns as expected:\n",
    "df = df_unordered_columns[\n",
    "    [\n",
    "        \"Student Name\",\n",
    "        \"Student E-mail\",\n",
    "        \"Student ID\",\n",
    "        \"Student Alternate ID\",\n",
    "        \"Categories\",\n",
    "        \"Tags\",\n",
    "        \"Classification\",\n",
    "        \"Major\",\n",
    "        \"Cumulative GPA\",\n",
    "        # \"Assigned Staff\",\n",
    "        \"Course Name\",\n",
    "        \"Course Number\",\n",
    "        \"Section\",\n",
    "        \"Instructors\",\n",
    "        \"Dropped?\",\n",
    "        \"Dropped Date\",\n",
    "        \"Midterm Grade\",\n",
    "        \"Final Grade\",\n",
    "        \"Total Progress Reports\",\n",
    "        \"Absences\",\n",
    "        # \"Unexcused Absences\",\n",
    "        # \"Excused Absences\",\n",
    "        \"Credit Hours\",\n",
    "        \"Start Date\",\n",
    "        \"End Date\",\n",
    "        \"Start Time\",\n",
    "        \"End Time\",\n",
    "        \"Class Days\",\n",
    "    ]\n",
    "].replace({None: np.NaN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EAB-tools-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

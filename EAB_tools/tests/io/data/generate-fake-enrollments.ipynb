{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code was mostly created by ChatGPT\n",
    "from __future__ import annotations\n",
    "\n",
    "import random\n",
    "\n",
    "from faker import Faker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from EAB_tools._testing.data_generation import (\n",
    "    EV,\n",
    "    generate_cumulative_gpas,\n",
    "    generate_emails,\n",
    "    generate_staff_df,\n",
    "    sample_from_dict,\n",
    "    select_assigned_staff,\n",
    "    select_categories,\n",
    "    select_tags,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locales_dict: dict[str, float] = {\n",
    "    \"en_US\": 90,\n",
    "    \"es_MX\": 5,\n",
    "    \"en_CA\": 2,\n",
    "    \"en_GB\": 1,\n",
    "    \"fr_FR\": 1,\n",
    "    \"de_DE\": 1,\n",
    "}\n",
    "fake = Faker(locales_dict)\n",
    "np.random.seed(42)  # Also sets the random seed for `pandas`\n",
    "Faker.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_records = 85_253"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_per_course_distribution: dict[float, float] = {\n",
    "    1: 0.5288,\n",
    "    2: 0.2028,\n",
    "    3: 0.0946,\n",
    "    4: 0.0601,\n",
    "    5: 0.0274,\n",
    "    6: 0.0286,\n",
    "    7: 0.0211,\n",
    "    8: 0.0033,\n",
    "    9: 0.0030,\n",
    "    10: 0.0051,\n",
    "    11: 0.0079,\n",
    "    12: 0.0031,\n",
    "    13: 0.0032,\n",
    "    15: 0.0029,\n",
    "    18: 0.0014,\n",
    "    19: 0.0016,\n",
    "    20: 0.0026,\n",
    "    24: 0.0012,\n",
    "    35: 0.0013,\n",
    "}\n",
    "\n",
    "instructors_per_course_distribution: dict[float, float] = {\n",
    "    0: 0.0609,\n",
    "    1: 0.9224,\n",
    "    2: 0.0168,\n",
    "}\n",
    "\n",
    "sections_per_instructor_distribution: dict[float, float] = {\n",
    "    1: 0.3148,\n",
    "    2: 0.3148,\n",
    "    3: 0.1872,\n",
    "    4: 0.0922,\n",
    "    5: 0.0425,\n",
    "    6: 0.0192,\n",
    "    7: 0.0149,\n",
    "    8: 0.0055,\n",
    "    9: 0.0036,\n",
    "    10: 0.0035,\n",
    "    15: 0.0018,\n",
    "}\n",
    "\n",
    "students_per_section_distribution: dict[float, float] = {\n",
    "    1: 0.0579,\n",
    "    2: 0.0373,\n",
    "    3: 0.0290,\n",
    "    4: 0.0413,\n",
    "    5: 0.0284,\n",
    "    6: 0.0472,\n",
    "    7: 0.0332,\n",
    "    8: 0.0263,\n",
    "    9: 0.0402,\n",
    "    10: 0.0409,\n",
    "    11: 0.0329,\n",
    "    12: 0.0358,\n",
    "    13: 0.0276,\n",
    "    14: 0.0274,\n",
    "    15: 0.0225,\n",
    "    16: 0.0326,\n",
    "    17: 0.0298,\n",
    "    18: 0.0215,\n",
    "    19: 0.0219,\n",
    "    20: 0.0158,\n",
    "    21: 0.0175,\n",
    "    22: 0.0194,\n",
    "    23: 0.0137,\n",
    "    24: 0.0176,\n",
    "    25: 0.0211,\n",
    "    26: 0.0209,\n",
    "    27: 0.0094,\n",
    "    28: 0.0167,\n",
    "    29: 0.0246,\n",
    "    30: 0.0110,\n",
    "    31: 0.0151,\n",
    "    32: 0.0112,\n",
    "    33: 0.0122,\n",
    "    34: 0.0130,\n",
    "    35: 0.0148,\n",
    "    36: 0.0157,\n",
    "    37: 0.0073,\n",
    "    38: 0.0159,\n",
    "    39: 0.0080,\n",
    "    40: 0.0091,\n",
    "    41: 0.0053,\n",
    "    42: 0.0057,\n",
    "    43: 0.0065,\n",
    "    44: 0.0040,\n",
    "    45: 0.0016,\n",
    "    46: 0.0033,\n",
    "    47: 0.0046,\n",
    "    48: 0.0027,\n",
    "    49: 0.0015,\n",
    "    50: 0.0040,\n",
    "    51: 0.0035,\n",
    "    52: 0.0016,\n",
    "    53: 0.0012,\n",
    "    54: 0.0019,\n",
    "    55: 0.0010,\n",
    "    56: 0.0020,\n",
    "    57: 0.0020,\n",
    "    59: 0.0013,\n",
    "    60: 0.0006,\n",
    "    63: 0.0005,\n",
    "    69: 0.0012,\n",
    "    111: 0.0005,\n",
    "}\n",
    "\n",
    "classifications_distribution: dict[str, float] = {\n",
    "    \"Foo (Winter 2024)\": 0.6120,\n",
    "    \"Foo (Fall 2023)\": 0.1859,\n",
    "    \"Graduate (Winter 2024)\": 0.0573,\n",
    "    \"None\": 0.0379,\n",
    "    \"Foo (Spring 2024)\": 0.0369,\n",
    "    \"Graduate (Fall 2023)\": 0.0160,\n",
    "    \"Foo (Spring 2023)\": 0.0151,\n",
    "    \"Foo (Summer 2023)\": 0.0130,\n",
    "    \"Foo (Winter 2023)\": 0.0064,\n",
    "    \"Foo (Fall 2022)\": 0.0053,\n",
    "    \"Graduate (Spring 2023)\": 0.0015,\n",
    "    \"Foo (Spring 2022)\": 0.0017,\n",
    "    \"Graduate (Summer 2023)\": 0.0014,\n",
    "    \"Graduate (Spring 2024)\": 0.0013,\n",
    "    \"Graduate (Winter 2023)\": 0.0010,\n",
    "    \"Graduate (Fall 2022)\": 0.0005,\n",
    "    \"Graduate (Summer 2022)\": 0.0005,\n",
    "    \"Foo (Fall 2021)\": 0.0005,\n",
    "    \"Foo (Spring 2020)\": 0.0004,\n",
    "    \"Foo (Fall 2019)\": 0.0003,\n",
    "    \"Foo (Summer 2024)\": 0.0004,\n",
    "    \"Foo (Winter 2022)\": 0.0004,\n",
    "    \"Foo (Summer 2022)\": 0.0003,\n",
    "    \"Graduate (Fall 2018)\": 0.0002,\n",
    "    \"Graduate (Winter 2022)\": 0.0002,\n",
    "    \"Foo (Fall 2020)\": 0.0002,\n",
    "    \"Foo (Winter 2019)\": 0.0002,\n",
    "    \"Foo (Winter 2020)\": 0.0002,\n",
    "    \"Graduate (Winter 2018)\": 0.0002,\n",
    "    \"Graduate (Spring 2021)\": 0.0002,\n",
    "    \"Foo (Winter 2017)\": 0.0002,\n",
    "    \"Graduate (Winter 2021)\": 0.0002,\n",
    "    \"Graduate (Summer 2021)\": 0.0002,\n",
    "    \"Freshman (Winter 2024)\": 0.0001,\n",
    "    \"Foo (Winter 2021)\": 0.0001,\n",
    "    \"Foo (Spring 2016)\": 0.0001,\n",
    "    \"Graduate (Spring 2017)\": 0.0001,\n",
    "    \"Graduate (Summer 2020)\": 0.0001,\n",
    "    \"Graduate (Spring 2020)\": 0.0001,\n",
    "    \"Foo (Spring 2019)\": 0.0001,\n",
    "    \"Graduate (Fall 2020)\": 0.0001,\n",
    "    \"Graduate (Spring 2019)\": 0.0001,\n",
    "    \"Graduate (Spring 2022)\": 0.0001,\n",
    "    \"Foo (Summer 2021)\": 0.0001,\n",
    "    \"Graduate (Fall 2021)\": 0.0001,\n",
    "    \"Foo (Fall 2016)\": 0.0001,\n",
    "    \"Foo (Summer 2019)\": 0.0001,\n",
    "    \"Freshman (Fall 2022)\": 0.0001,\n",
    "    \"Graduate (Summer 2024)\": 0.0001,\n",
    "    \"Foo (Fall 2024)\": 0.0001,\n",
    "    \"Foo (Spring 2021)\": 0.0001,\n",
    "}\n",
    "\n",
    "num_courses_per_student_distribution: dict[float, float] = {\n",
    "    1: 0.1870,\n",
    "    2: 0.2159,\n",
    "    3: 0.2484,\n",
    "    4: 0.1562,\n",
    "    5: 0.0881,\n",
    "    6: 0.0480,\n",
    "    7: 0.0226,\n",
    "    8: 0.0105,\n",
    "    9: 0.0067,\n",
    "    10: 0.0056,\n",
    "    11: 0.0018,\n",
    "    12: 0.0053,\n",
    "    13: 0.0027,\n",
    "    14: 0.0005,\n",
    "    15: 0.0001,\n",
    "    16: 0.0005,\n",
    "    17: 0.0002,\n",
    "}\n",
    "\n",
    "credit_hours_per_student_distribution: dict[float, float] = {\n",
    "    0: 0.14,\n",
    "    1: 0.05,\n",
    "    2: 0.07,\n",
    "    3: 0.26,\n",
    "    4: 0.01,\n",
    "    5: 0.44,\n",
    "    6: 0.02,\n",
    "    12: 0.01,\n",
    "}\n",
    "\n",
    "start_times_distribution: dict[str, float] = {\n",
    "    \"7:00 AM\": 0.01,\n",
    "    \"8:00 AM\": 0.06,\n",
    "    \"9:00 AM\": 0.29,\n",
    "    \"10:00 AM\": 0.06,\n",
    "    \"10:30 AM\": 0.03,\n",
    "    \"11:00 AM\": 0.06,\n",
    "    \"12:00 PM\": 0.01,\n",
    "    \"1:00 PM\": 0.29,\n",
    "    \"2:00 PM\": 0.03,\n",
    "    \"3:00 PM\": 0.05,\n",
    "    \"4:00 PM\": 0.05,\n",
    "    \"4:30 PM\": 0.05,\n",
    "    \"5:00 PM\": 0.02,\n",
    "    \"6:00 PM\": 0.01,\n",
    "    \"6:30 PM\": 0.01,\n",
    "}\n",
    "\n",
    "course_duration_distribution: dict[pd.Timedelta, float] = {\n",
    "    pd.to_timedelta(time): prob\n",
    "    for time, prob in {\n",
    "        \"30 min\": 0.01,\n",
    "        \"1 hr\": 0.03,\n",
    "        \"75 min\": 0.17,\n",
    "        \"2 hr\": 0.05,\n",
    "        \"150 min\": 0.05,\n",
    "        \"3 hr\": 0.56,\n",
    "        \"4 hr\": 0.05,\n",
    "        \"5 hr\": 0.04,\n",
    "        \"6 hr\": 0.02,\n",
    "        \"7 hr\": 0.01,\n",
    "        \"8 hr\": 0.01,\n",
    "    }.items()\n",
    "}\n",
    "\n",
    "class_days_distribution: dict[str | None, float] = {\n",
    "    None: 0.14,\n",
    "    \"MWF\": 0.14,\n",
    "    \"TR\": 0.14,\n",
    "    \"T\": 0.11,\n",
    "    \"R\": 0.10,\n",
    "    \"MW\": 0.10,\n",
    "    \"W\": 0.08,\n",
    "    \"M\": 0.07,\n",
    "    \"MTWRF\": 0.05,\n",
    "    \"Sa\": 0.03,\n",
    "    \"F\": 0.03,\n",
    "    \"WR\": 0.01,\n",
    "    \"MTWR\": 0.01,\n",
    "}\n",
    "\n",
    "assigned_staff_role_probabilities: dict[str, float] = {\n",
    "    \"Advisor\": 0.90,\n",
    "    \"Career Advisor\": 0.80,\n",
    "    \"Professor\": 0.20,\n",
    "    \"Student Finance\": 0.10,\n",
    "    \"FAFSA coordinator\": 0.10,\n",
    "    \"International Success Advisor\": 0.02,\n",
    "    \"Field Advisor\": 0.01,\n",
    "    \"VA coordinator\": 0.01,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sections_per_course = EV(sections_per_course_distribution)\n",
    "avg_instructors_per_course = EV(instructors_per_course_distribution)\n",
    "avg_sections_per_instructor = EV(sections_per_instructor_distribution)\n",
    "avg_students_per_section = EV(students_per_section_distribution)\n",
    "avg_courses_per_student = EV(num_courses_per_student_distribution)\n",
    "avg_credit_hours_per_student = EV(credit_hours_per_student_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of unique students based on the average number of courses per\n",
    "# student\n",
    "n_unique_students = int(n_records / avg_courses_per_student)\n",
    "\n",
    "majors = (\n",
    "    \"Accounting,Anthropology,Biochemistry,Biological Sciences,Business Administration,\"\n",
    "    \"Chemical Engineering,Civil Engineering,Computer Science,Economics,\"\n",
    "    \"Electrical Engineering,English Literature,Environmental Science,Finance,\"\n",
    "    \"Graphic Design,History,Information Technology,Journalism,Marketing,Mathematics,\"\n",
    "    \"Mechanical Engineering,Music,Nursing,Philosophy,Physics,Political Science,\"\n",
    "    \"Psychology,Sociology,Software Engineering,Statistics,Theater Arts\"\n",
    ").split(\",\")\n",
    "\n",
    "# Generate unique student data\n",
    "unique_students = pd.DataFrame(\n",
    "    {\n",
    "        \"Student ID\": [\n",
    "            # The builtin `random.sample` method from the Python standard lib can\n",
    "            # efficiently sample from `range` objects, while `np.random.sample` needs to\n",
    "            # construct the entire list in memory first.\n",
    "            f\"ID{rand_id:09}\"\n",
    "            for rand_id in random.sample(range(10**9), n_unique_students)\n",
    "        ],\n",
    "        \"Student Alternate ID\": np.NaN,\n",
    "        \"Student Name\": [\n",
    "            f\"{fake[locale].last_name()}, {fake[locale].first_name()}\"\n",
    "            for locale in sample_from_dict(locales_dict, size=n_unique_students)\n",
    "        ],\n",
    "        \"Classification\": sample_from_dict(\n",
    "            classifications_distribution, size=n_unique_students\n",
    "        ),\n",
    "        \"Major\": np.random.choice(majors, n_unique_students),\n",
    "        \"Credit Hours\": sample_from_dict(\n",
    "            credit_hours_per_student_distribution, size=n_unique_students\n",
    "        ),\n",
    "    }\n",
    ").replace(\"None\", np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_students[\"Student E-mail\"] = generate_emails(unique_students[\"Student Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_emails = unique_students[\"Student E-mail\"].copy()\n",
    "existing_ids = unique_students[\"Student ID\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Categories\n",
    "unique_students[\"Categories\"] = select_categories(n_unique_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_students[\"Tags\"] = select_tags(n_unique_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_students[\"Cumulative GPA\"] = generate_cumulative_gpas(len(unique_students))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_staff_role_probabilities_no_professor = {\n",
    "    role: prob\n",
    "    for role, prob in assigned_staff_role_probabilities.items()\n",
    "    if role.casefold() != \"professor\"\n",
    "}\n",
    "staff_df = generate_staff_df(\n",
    "    fake=fake,\n",
    "    assigned_staff_role_probabilities=assigned_staff_role_probabilities_no_professor,\n",
    "    n_staff=n_unique_students // 40,\n",
    "    existing_emails=existing_emails,\n",
    "    existing_ids=existing_ids,\n",
    ")\n",
    "\n",
    "unique_students[\"Assigned Staff\"] = select_assigned_staff(\n",
    "    staff_df, assigned_staff_role_probabilities, n_unique_students\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_emails = pd.concat([existing_emails, staff_df[\"email\"]])\n",
    "existing_ids = pd.concat([existing_ids, staff_df[\"id\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_courses_per_student = sample_from_dict(\n",
    "    num_courses_per_student_distribution, size=n_unique_students\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicate each student entry based on the number of courses they're taking\n",
    "replicated_students = unique_students.loc[\n",
    "    unique_students.index.repeat(num_courses_per_student)\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Course info\n",
    "# Generate a course schedule to assign students courses\n",
    "n_course_numbers_needed = np.ceil(\n",
    "    n_records / avg_students_per_section / avg_sections_per_course\n",
    ").astype(int)\n",
    "\n",
    "n_instructors_needed = np.ceil(\n",
    "    n_course_numbers_needed / avg_sections_per_instructor\n",
    ").astype(int)\n",
    "\n",
    "n_sections_per_course = sample_from_dict(\n",
    "    sections_per_course_distribution, size=n_course_numbers_needed\n",
    ")\n",
    "\n",
    "section_id_nums = np.random.choice(\n",
    "    np.arange(10**4, 10**5), size=sum(n_sections_per_course), replace=False\n",
    ")\n",
    "\n",
    "course_depts = (\n",
    "    \"AAS,AHS,ANT,ART,CAN,CIN,COM,CSC,DES,EAS,EDL,EDU,ENG,FME,GEN,HIS,HSC,LAN,LAS,LAW,\"\n",
    "    \"MED,MTH,MUS,NUR,OBG,OPH,PHA,PHE,PHY,PTH,QRM,RAC,ROM,SCI,SCW,SLV,SOC,STT,SUR,THR,\"\n",
    "    \"URB,VIA\"\n",
    ").split(\",\")\n",
    "course_number_ints = sample_from_dict(\n",
    "    {\n",
    "        i: 1 / i  # Higher course numbers map to lower probabilities\n",
    "        for i in range(95, 601)  # Course numbers can fall between 95 and 601\n",
    "    },\n",
    "    size=180,\n",
    "    replace=False,\n",
    ")\n",
    "\n",
    "\n",
    "# Add some course numbers that we definitely want to see\n",
    "course_numbers_set = set(course_number_ints) | {101, 200, 600, \"115L\", \"105H\"}\n",
    "course_numbers_list = sorted(f\"{x:03}\" for x in course_numbers_set)\n",
    "\n",
    "\n",
    "course_numbers = (\n",
    "    pd.Series(\n",
    "        f\"{course_dept}-{course_number:03}\"\n",
    "        for course_dept in course_depts\n",
    "        for course_number in course_numbers_list\n",
    "    )\n",
    "    .sample(n_course_numbers_needed)\n",
    "    .sort_values(ignore_index=True)\n",
    ")\n",
    "\n",
    "course_names = pd.Series(\n",
    "    fake[\"en_US\"].unique.sentence(nb_words=6) for _ in range(n_course_numbers_needed)\n",
    ").str.replace(\n",
    "    r\"\\.$\", \"\", regex=True  # strip the final period\n",
    ")\n",
    "\n",
    "\n",
    "course_schedule_list = []\n",
    "for course_number, course_name, num_course_sections, section_id_num in zip(\n",
    "    course_numbers, course_names, n_sections_per_course, section_id_nums\n",
    "):\n",
    "    for _section_num in range(num_course_sections):\n",
    "        course_schedule_list.append(\n",
    "            {\n",
    "                \"Course Number\": course_number,\n",
    "                \"Course Name\": course_name,\n",
    "                \"Section\": section_id_num,\n",
    "            }\n",
    "        )\n",
    "\n",
    "course_schedule = pd.DataFrame(course_schedule_list)\n",
    "\n",
    "course_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructors_df = pd.DataFrame()\n",
    "instructors_df[\"instructor_names\"] = pd.Series(\n",
    "    [\n",
    "        f\"{fake[locale].last_name()}, {fake[locale].first_name()}\"\n",
    "        for locale in sample_from_dict(locales_dict, size=n_instructors_needed)\n",
    "    ]\n",
    ")\n",
    "instructors_df[\"instructor_emails\"] = generate_emails(\n",
    "    instructors_df[\"instructor_names\"],\n",
    "    existing_emails=existing_emails,\n",
    ")\n",
    "existing_emails = pd.concat([existing_emails, instructors_df[\"instructor_emails\"]])\n",
    "\n",
    "instructors_df[\"instructor_id\"] = pd.NA\n",
    "while instructors_df[\"instructor_id\"].isna().any():\n",
    "    # Repeat the ID number assignment if anyone overlaps with a Student ID or Staff ID\n",
    "    # (even tho this is EXTREMELY unlikely!)\n",
    "    instructors_df[\"instructor_id\"] = [\n",
    "        f\"ID{rand_id:09}\" if f\"ID{rand_id:09}\" not in existing_ids else pd.NA\n",
    "        for rand_id in random.sample(range(10**9), n_instructors_needed)\n",
    "    ]\n",
    "existing_ids = pd.concat([existing_ids, instructors_df[\"instructor_id\"]])\n",
    "\n",
    "\n",
    "instructors_df[\"is_assignable_as_staff\"] = np.random.choice(\n",
    "    [True, False],\n",
    "    size=len(instructors_df),\n",
    "    p=[\n",
    "        assigned_staff_role_probabilities[\"Professor\"],\n",
    "        1 - assigned_staff_role_probabilities.pop(\"Professor\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "instructors_df[\"name_email_formatted\"] = (\n",
    "    instructors_df[\"instructor_names\"]\n",
    "    + \" (\"\n",
    "    + instructors_df[\"instructor_id\"]\n",
    "    + \") <\"\n",
    "    + instructors_df[\"instructor_emails\"]\n",
    "    + \">\"\n",
    ")\n",
    "\n",
    "num_instructors_per_section = sample_from_dict(\n",
    "    instructors_per_course_distribution, len(course_schedule)\n",
    ")\n",
    "\n",
    "course_schedule[\"Instructors\"] = [\n",
    "    (\n",
    "        \"; \".join(instructors_df[\"name_email_formatted\"].sample(n).sort_values())\n",
    "        if n > 0\n",
    "        else None\n",
    "    )\n",
    "    for n in num_instructors_per_section\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schedule information\n",
    "# Start Date & End Date\n",
    "course_schedule[\"Start Date\"] = [\n",
    "    fake.date_between(start_date=\"-3m\", end_date=\"+3m\")\n",
    "    for _ in range(len(course_schedule))\n",
    "]\n",
    "course_schedule[\"End Date\"] = course_schedule[\"Start Date\"] + pd.Timedelta(weeks=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Time & End Time\n",
    "course_schedule[\"Start Time\"] = sample_from_dict(\n",
    "    start_times_distribution, size=len(course_schedule)\n",
    ")\n",
    "\n",
    "\n",
    "LATEST_POSSIBLE_END_TIME = pd.to_datetime(\"10:00 PM\", format=\"%I:%M %p\")\n",
    "\n",
    "potential_end_times_with_arbitrary_date = (\n",
    "    pd.to_datetime(\n",
    "        course_schedule[\"Start Time\"].str.replace(\" CT\", \"\"), format=\"%I:%M %p\"\n",
    "    )\n",
    "    + (\n",
    "        sample_from_dict(\n",
    "            course_duration_distribution, size=len(course_schedule)\n",
    "        ).astype(\"timedelta64\")\n",
    "    )\n",
    ").rename(\"Potential End Times\")\n",
    "\n",
    "potential_end_times_with_arbitrary_date.loc[\n",
    "    potential_end_times_with_arbitrary_date > LATEST_POSSIBLE_END_TIME\n",
    "] = LATEST_POSSIBLE_END_TIME\n",
    "\n",
    "course_schedule[\"End Time\"] = (\n",
    "    potential_end_times_with_arbitrary_date.dt.strftime(\"%I:%M %p\")\n",
    "    .str.lstrip(\"0\")\n",
    "    .rename(\"End Time\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Days\n",
    "course_schedule[\"Class Days\"] = sample_from_dict(\n",
    "    class_days_distribution, len(course_schedule)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the total number of courses needed by summing up courses for each student\n",
    "total_courses_needed = num_courses_per_student.sum()\n",
    "\n",
    "# Generate a random course index for each needed course\n",
    "random_course_indices = np.random.choice(\n",
    "    course_schedule.index, size=total_courses_needed, replace=True\n",
    ")\n",
    "\n",
    "# Assign these random course indices to each student based on how many courses they need\n",
    "student_course_indices = np.split(\n",
    "    random_course_indices, np.cumsum(num_courses_per_student)[:-1]\n",
    ")\n",
    "\n",
    "# Create a DataFrame for replicated students\n",
    "replicated_students = pd.DataFrame(\n",
    "    {\n",
    "        \"Student ID\": np.repeat(unique_students[\"Student ID\"], num_courses_per_student),\n",
    "        \"Course Index\": np.concatenate(student_course_indices),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Merge the replicated students DataFrame with the course schedule using the course\n",
    "# index. Then, drop the \"Course Index\" column as it's no longer needed. Finally, drop\n",
    "# duplicate enrollments for each student (this behavior may change in the future).\n",
    "replicated_students = (\n",
    "    replicated_students.merge(\n",
    "        course_schedule.reset_index(),\n",
    "        left_on=\"Course Index\",\n",
    "        right_index=True,\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .drop(columns=[\"Course Index\"])\n",
    "    .drop_duplicates([\"Student ID\", \"Course Number\"])\n",
    ")\n",
    "\n",
    "# Merge with unique_students to get student details\n",
    "replicated_students = replicated_students.merge(\n",
    "    unique_students, on=\"Student ID\", how=\"left\"\n",
    ")\n",
    "\n",
    "replicated_students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Professors to \"Assigned Staff\"\n",
    "# Explode the instructors list, since some sections will have multiple instructors\n",
    "exploded_instructors = (\n",
    "    replicated_students[\"Instructors\"].str.split(\"; \").explode().dropna().to_frame()\n",
    ")\n",
    "\n",
    "# Add the student IDs to each row, aligning on the index\n",
    "exploded_instructors[\"Student ID\"] = replicated_students[\"Student ID\"]\n",
    "\n",
    "# Merge the info from the `instructors_df`\n",
    "# we only care about those instructors who are assignable as staff\n",
    "merged_enrollment_instructor_data = exploded_instructors.merge(\n",
    "    instructors_df[instructors_df[\"is_assignable_as_staff\"]],\n",
    "    left_on=\"Instructors\",\n",
    "    right_on=\"name_email_formatted\",\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "# Use a regex to format the names how we'd like for the \"Assigned Staff\" column\n",
    "merged_enrollment_instructor_data[\n",
    "    \"Assigned Professors\"\n",
    "] = merged_enrollment_instructor_data[\"instructor_names\"].str.replace(\n",
    "    r\"^(?P<last>[\\w '\\-]+), (?P<first>[\\w '\\-]+)$\",\n",
    "    r\"\\g<first> \\g<last> (Professor)\",\n",
    "    regex=True,\n",
    ")\n",
    "\n",
    "# Group the staff by instructors and `\", \".join` them\n",
    "assigned_professors = merged_enrollment_instructor_data.groupby(\"Student ID\")[\n",
    "    \"Assigned Professors\"\n",
    "].agg(\", \".join)\n",
    "\n",
    "# Merge the assigned staff back to our enrollments report\n",
    "replicated_students[\"Assigned Staff\"] = (\n",
    "    replicated_students[[\"Student ID\", \"Assigned Staff\"]]\n",
    "    .merge(\n",
    "        assigned_professors,\n",
    "        how=\"left\",\n",
    "        left_on=\"Student ID\",\n",
    "        right_index=True,\n",
    "    )\n",
    "    .fillna(\"\")\n",
    "    .apply(\n",
    "        lambda x: x[\"Assigned Staff\"]\n",
    "        + (\", \" if x[\"Assigned Staff\"] and x[\"Assigned Professors\"] else \"\")\n",
    "        + x[\"Assigned Professors\"],\n",
    "        axis=\"columns\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alphabetize each student's \"Assigned Staff\"\n",
    "replicated_students[\"Assigned Staff\"] = (\n",
    "    replicated_students[\"Assigned Staff\"].str.split(\", \").apply(sorted).apply(\", \".join)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrollment info\n",
    "replicated_students[\"Dropped?\"] = sample_from_dict(\n",
    "    {\"Yes\": 0.24, \"No\": 0.76}, size=len(replicated_students)\n",
    ")\n",
    "replicated_students[\"Dropped Date\"] = dropped_dates = [\n",
    "    fake.date_between(start_date=\"-1y\", end_date=\"today\") if drop == \"Yes\" else None\n",
    "    for drop in replicated_students[\"Dropped?\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add other enrollment-specific information (e.g., grades, attendance) in a similar\n",
    "# manner\n",
    "replicated_students[\"Midterm Grade\"] = np.random.choice(\n",
    "    [\"A\", \"B\", \"C\", \"D\", \"F\"], len(replicated_students)\n",
    ")\n",
    "replicated_students[\"Final Grade\"] = np.random.choice(\n",
    "    [\"A\", \"B\", \"C\", \"D\", \"F\"], len(replicated_students)\n",
    ")\n",
    "replicated_students[\"Total Progress Reports\"] = np.random.poisson(\n",
    "    0.4, len(replicated_students)\n",
    ")\n",
    "\n",
    "# The proportion of students with 0 absences\n",
    "PERFECT_ATTENDANCE_RATE = 0.85\n",
    "# Model the distribution of non-zero absences\n",
    "replicated_students[\"Absences\"] = replicated_students[\"Unexcused Absences\"] = (\n",
    "    np.random.poisson(2.84, size=len(replicated_students)).clip(min=1)\n",
    ")\n",
    "# Replace `PERFECT_ATTENDANCE_RATE` proportion of records with 0 absences\n",
    "replicated_students.loc[\n",
    "    np.random.rand(len(replicated_students)) > PERFECT_ATTENDANCE_RATE, \"Absences\"\n",
    "] = 0\n",
    "replicated_students[\"Excused Absences\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "# and ensure that the dataframe is not longer than `n_records`\n",
    "df_unordered_columns = replicated_students.iloc[:n_records]\n",
    "\n",
    "# Order the columns as expected:\n",
    "df = df_unordered_columns[\n",
    "    [\n",
    "        \"Student Name\",\n",
    "        \"Student E-mail\",\n",
    "        \"Student ID\",\n",
    "        \"Student Alternate ID\",\n",
    "        \"Categories\",\n",
    "        \"Tags\",\n",
    "        \"Classification\",\n",
    "        \"Major\",\n",
    "        \"Cumulative GPA\",\n",
    "        \"Assigned Staff\",\n",
    "        \"Course Name\",\n",
    "        \"Course Number\",\n",
    "        \"Section\",\n",
    "        \"Instructors\",\n",
    "        \"Dropped?\",\n",
    "        \"Dropped Date\",\n",
    "        \"Midterm Grade\",\n",
    "        \"Final Grade\",\n",
    "        \"Total Progress Reports\",\n",
    "        \"Absences\",\n",
    "        \"Unexcused Absences\",\n",
    "        \"Excused Absences\",\n",
    "        \"Credit Hours\",\n",
    "        \"Start Date\",\n",
    "        \"End Date\",\n",
    "        \"Start Time\",\n",
    "        \"End Time\",\n",
    "        \"Class Days\",\n",
    "    ]\n",
    "].replace({None: np.NaN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EAB-tools-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
